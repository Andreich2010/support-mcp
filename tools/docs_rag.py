"""–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ª–æ–∫–∞–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π (–ø—Ä–æ—Å—Ç–µ–π—à–∏–π RAG)."""

import os
import re
from pathlib import Path
from typing import Any, Dict, List

from mcp.server.fastmcp import Context
from mcp.types import TextContent
from opentelemetry import trace
from pydantic import Field

from mcp_instance import mcp
from .utils import ToolResult

tracer = trace.get_tracer(__name__)


# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ (–ù–ï MCP-–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã) ---


def _get_docs_dir() -> Path:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä–Ω–µ–≤–æ–π –∫–∞—Ç–∞–ª–æ–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.

    –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: ./docs
    –ú–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è DOCS_DIR.
    """
    docs_dir = os.getenv("DOCS_DIR", "docs")
    return Path(docs_dir).resolve()


def _iter_doc_files() -> List[Path]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ (md, rst, txt) –≤ –∫–∞—Ç–∞–ª–æ–≥–µ docs.
    """
    base = _get_docs_dir()
    if not base.exists() or not base.is_dir():
        return []

    exts = {".md", ".rst", ".txt"}
    files: List[Path] = []
    files.extend(
        path
        for path in base.rglob("*")
        if path.is_file() and path.suffix.lower() in exts
    )
    return files


def _simple_score(text: str, query: str) -> int:
    """
    –ü—Ä–æ—Å—Ç–µ–π—à–∏–π —Å–∫–æ—Ä–∏–Ω–≥: —Å—á–∏—Ç–∞–µ–º –≤—Ö–æ–∂–¥–µ–Ω–∏—è —Å–ª–æ–≤ –∑–∞–ø—Ä–æ—Å–∞ –≤ —Ç–µ–∫—Å—Ç–µ.
    """
    text_lower = text.lower()
    tokens = re.findall(r"\w+", query.lower())
    return sum(text_lower.count(tok) for tok in tokens if tok)


def _search_in_file(path: Path, query: str, max_snippets: int = 3) -> List[Dict[str, Any]]:
    """
    –ò—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –≤ –æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–Ω–∏–ø–ø–µ—Ç—ã.
    """
    try:
        content = path.read_text(encoding="utf-8", errors="ignore")
    except OSError:
        return []

    # –†–∞–∑–æ–±—å—ë–º –ø–æ "–∞–±–∑–∞—Ü–∞–º" (–ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∫–∞–∫ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏)
    raw_paragraphs = re.split(r"\n\s*\n", content)
    snippets: List[Dict[str, Any]] = []

    for para in raw_paragraphs:
        para_stripped = para.strip()
        if not para_stripped:
            continue

        score = _simple_score(para_stripped, query)
        if score <= 0:
            continue

        # –û–≥—Ä–∞–Ω–∏—á–∏–º —Ä–∞–∑–º–µ—Ä —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞
        if len(para_stripped) > 600:
            para_stripped = f"{para_stripped[:600]}..."

        snippets.append(
            {
                "file": str(path),
                "score": score,
                "snippet": para_stripped,
            }
        )

    # –û—Ç—Å–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
    snippets.sort(key=lambda x: x["score"], reverse=True)
    return snippets[:max_snippets]


def _search_docs_internal(query: str, max_results: int = 10) -> List[Dict[str, Any]]:
    """
    –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –ø–æ –≤—Å–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º.
    """
    files = _iter_doc_files()
    all_snippets: List[Dict[str, Any]] = []

    for f in files:
        snippets = _search_in_file(f, query, max_snippets=3)
        all_snippets.extend(snippets)

    all_snippets.sort(key=lambda x: x["score"], reverse=True)
    return all_snippets[:max_results]


# --- MCP-–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã ---


@mcp.tool()
async def list_docs(ctx: Context | None = None) -> ToolResult:
    """
    üìö –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.
    """
    from mcp.shared.exceptions import McpError, ErrorData

    if ctx is None:
        ctx = Context()

    with tracer.start_as_current_span("list_docs"):
        try:
            docs_dir = _get_docs_dir()
            files = _iter_doc_files()

            if not files:
                text = (
                    f"–ö–∞—Ç–∞–ª–æ–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –ø—É—Å—Ç: {docs_dir}\n"
                    "–°–æ–∑–¥–∞–π—Ç–µ –ø–∞–ø–∫—É docs/ –∏ –¥–æ–±–∞–≤—å—Ç–µ —Ç—É–¥–∞ .md / .rst / .txt —Ñ–∞–π–ª—ã."
                )
            else:
                rels = [str(p.relative_to(docs_dir)) for p in files]
                lines = ["–ù–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:"]
                lines.extend(f"- {r}" for r in rels)
                text = "\n".join(lines)

            return ToolResult(
                content=[TextContent(type="text", text=text)],
                structured_content={
                    "docs_dir": str(docs_dir),
                    "files": [str(p) for p in files],
                },
            )

        except Exception as e:  # noqa: BLE001
            await ctx.error(f"üí• –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: {e}")
            raise McpError(
                ErrorData(
                    code=-32603,
                    message=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: {e}",
                )
            ) from e


@mcp.tool()
async def search_docs(
    query: str = Field(
        ...,
        min_length=1,
        description="–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.",
    ),
    max_results: int = Field(
        default=5,
        ge=1,
        le=20,
        description="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤.",
    ),
    ctx: Context | None = None,
) -> ToolResult:
    """
    üîé –ü–æ–∏—Å–∫ –ø–æ –ª–æ–∫–∞–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ (–ø—Ä–æ—Å—Ç–æ–π full-text).
    """
    from mcp.shared.exceptions import McpError, ErrorData

    if ctx is None:
        ctx = Context()

    with tracer.start_as_current_span("search_docs") as span:
        span.set_attribute("query", query)
        span.set_attribute("max_results", max_results)

        try:
            await ctx.info(f"üîé –ò—â–µ–º –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: {query!r}")
            await ctx.report_progress(progress=0, total=100)

            snippets = _search_docs_internal(query=query, max_results=max_results)

            if not snippets:
                text = f"–ü–æ –∑–∞–ø—Ä–æ—Å—É {query!r} –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏."
            else:
                lines = [f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É {query!r}:"]
                lines.extend(
                    f"\nüìÑ {s['file']} (score={s['score']}):\n{s['snippet']}"
                    for s in snippets
                )
                text = "\n".join(lines)

            await ctx.report_progress(progress=100, total=100)

            return ToolResult(
                content=[TextContent(type="text", text=text)],
                structured_content={"results": snippets},
                meta={"query": query},
            )

        except Exception as e:  # noqa: BLE001
            await ctx.error(f"üí• –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: {e}")
            raise McpError(
                ErrorData(
                    code=-32603,
                    message=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: {e}",
                )
            ) from e


@mcp.tool()
async def answer_from_docs(
    query: str = Field(
        ...,
        min_length=1,
        description="–í–æ–ø—Ä–æ—Å –∫ —Å–∏—Å—Ç–µ–º–µ, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –æ—Ç–≤–µ—Ç–∏—Ç—å, –æ–ø–∏—Ä–∞—è—Å—å –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é.",
    ),
    max_context_fragments: int = Field(
        default=5,
        ge=1,
        le=20,
        description="–°–∫–æ–ª—å–∫–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤–∫–ª—é—á–∞—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞.",
    ),
    ctx: Context | None = None,
) -> ToolResult:
    """
    üìò –û—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ (–ø—Ä–æ—Å—Ç–µ–π—à–∏–π RAG).

    –í–ê–ñ–ù–û: —Å–∞–º MCP-—Å–µ—Ä–≤–µ—Ä –ù–ï –≤—ã–∑—ã–≤–∞–µ—Ç LLM.
    –û–Ω –ø–æ–¥–±–∏—Ä–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Ö,
    –∞ —É–∂–µ –º–æ–¥–µ–ª—å-—Ö–æ—Å—Ç (–∞–≥–µ–Ω—Ç) —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç.
    """
    from mcp.shared.exceptions import McpError, ErrorData

    if ctx is None:
        ctx = Context()

    with tracer.start_as_current_span("answer_from_docs") as span:
        span.set_attribute("query", query)
        span.set_attribute("max_context_fragments", max_context_fragments)

        try:
            await ctx.info(f"üìò –û—Ç–≤–µ—á–∞–µ–º –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: {query!r}")
            await ctx.report_progress(progress=0, total=100)

            snippets = _search_docs_internal(
                query=query,
                max_results=max_context_fragments,
            )

            if not snippets:
                text = (
                    f"–í –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–µ –Ω–∞—à–ª–æ—Å—å –Ω–∏—á–µ–≥–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É {query!r}. "
                    "MCP-—Å–µ—Ä–≤–µ—Ä –Ω–µ –º–æ–∂–µ—Ç –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."
                )
                return ToolResult(
                    content=[TextContent(type="text", text=text)],
                    structured_content={
                        "answer": None,
                        "used_snippets": [],
                        "query": query,
                    },
                )

            # –°–æ–±–∏—Ä–∞–µ–º —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç: –ø–æ–∫–∞–∂–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
            lines: List[str] = [
                "–ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω—ã —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å.",
                f"–í–æ–ø—Ä–æ—Å: {query!r}",
                "",
            ]
            lines.extend(
                f"### –§—Ä–∞–≥–º–µ–Ω—Ç {idx} (score={s['score']}, file={s['file']}):\n{s['snippet']}\n"
                for idx, s in enumerate(snippets, start=1)
            )
            text = "\n".join(lines)

            await ctx.report_progress(progress=100, total=100)

            # 'answer' –∑–¥–µ—Å—å ‚Äî —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.
            # –ú–æ–¥–µ–ª—å-—Ö–æ—Å—Ç –º–æ–∂–µ—Ç –Ω–∞ –µ–≥–æ –æ—Å–Ω–æ–≤–µ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç.
            return ToolResult(
                content=[TextContent(type="text", text=text)],
                structured_content={
                    "answer": text,
                    "used_snippets": snippets,
                    "query": query,
                },
            )

        except Exception as e:  # noqa: BLE001
            await ctx.error(f"üí• –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–≤–µ—Ç–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: {e}")
            raise McpError(
                ErrorData(
                    code=-32603,
                    message=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–≤–µ—Ç–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: {e}",
                )
            ) from e
